{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will work on a partial dataset with only 4 categories out of the 20 \n",
    "#available in the dataset:\n",
    "categories = ['alt.atheism', 'soc.religion.christian',\n",
    "              'comp.graphics', 'sci.med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From: sd345@city.ac.uk (Michael Collier)\\nSubject: Converting images to HP LaserJet III?\\nNntp-Posting-Host: hampton\\nOrganization: The City University\\nLines: 14\\n\\nDoes anyone know of a good way (standard PC application/PD utility) to\\nconvert tif/img/tga files into LaserJet III format.  We would also like to\\ndo the same, converting to HPGL (HP plotter) files.\\n\\nPlease email any response.\\n\\nIs this the correct group?\\n\\nThanks in advance.  Michael.\\n-- \\nMichael Collier (Programmer)                 The Computer Unit,\\nEmail: M.P.Collier@uk.ac.city                The City University,\\nTel: 071 477-8000 x3769                      London,\\nFax: 071 477-8565                            EC1V 0HB.\\n',\n",
       " \"From: ani@ms.uky.edu (Aniruddha B. Deglurkar)\\nSubject: help: Splitting a trimming region along a mesh \\nOrganization: University Of Kentucky, Dept. of Math Sciences\\nLines: 28\\n\\n\\n\\n\\tHi,\\n\\n\\tI have a problem, I hope some of the 'gurus' can help me solve.\\n\\n\\tBackground of the problem:\\n\\tI have a rectangular mesh in the uv domain, i.e  the mesh is a \\n\\tmapping of a 3d Bezier patch into 2d. The area in this domain\\n\\twhich is inside a trimming loop had to be rendered. The trimming\\n\\tloop is a set of 2d Bezier curve segments.\\n\\tFor the sake of notation: the mesh is made up of cells.\\n\\n\\tMy problem is this :\\n\\tThe trimming area has to be split up into individual smaller\\n\\tcells bounded by the trimming curve segments. If a cell\\n\\tis wholly inside the area...then it is output as a whole ,\\n\\telse it is trivially rejected. \\n\\n\\tDoes any body know how thiss can be done, or is there any algo. \\n\\tsomewhere for doing this.\\n\\n\\tAny help would be appreciated.\\n\\n\\tThanks, \\n\\tAni.\\n-- \\nTo get irritated is human, to stay cool, divine.\\n\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the list of files matching those categories\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)\n",
    "twenty_train.data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism', 'comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The returned dataset is a scikit-learn “bunch”: \n",
    "# a simple holder object with fields that can be both accessed \n",
    "# as python dict keys or object attributes for convenience, \n",
    "# for instance the target_names holds the list of the \n",
    "# requested category names:\n",
    "twenty_train.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2257"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The files themselves are loaded in memory in the data attribute.\n",
    "len(twenty_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['From: sd345@city.ac.uk (Michael Collier)',\n",
       " 'Subject: Converting images to HP LaserJet III?',\n",
       " 'Nntp-Posting-Host: hampton']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.data[0].split(\"\\n\")[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Does anyone know of a good way (standard PC application/PD utility) to\n",
      "convert tif/img/tga files into LaserJet III format.  We would also like to\n",
      "do the same, converting to HPGL (HP plotter) files.\n",
      "\n",
      "*\n",
      "comp.graphics\n"
     ]
    }
   ],
   "source": [
    "# print the first lines of the first loaded file\n",
    "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[5:10]))\n",
    "print(\"*\")\n",
    "print(twenty_train.target_names[twenty_train.target[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 3, 3, 3, 3, 3, 2, 2, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For speed and space efficiency reasons scikit-learn \n",
    "# loads the target attribute as an array of integers that \n",
    "# corresponds to the index of the category name in the \n",
    "# target_names list. The category integer id \n",
    "# of each sample is stored in the target attribute:\n",
    "twenty_train.target[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.graphics\n",
      "comp.graphics\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n",
      "soc.religion.christian\n",
      "sci.med\n",
      "sci.med\n",
      "sci.med\n"
     ]
    }
   ],
   "source": [
    "for t in twenty_train.target[:10]:\n",
    "    print(twenty_train.target_names[t])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## turn the text content into numerical feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text preprocessing, tokenizing and filtering of stopwords \n",
    "# use count vectorize for bag of words to represent sentences as \n",
    "# feature vectors with word count for each word vector\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4690"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer supports counts of N-grams of words or consecutive characters. \n",
    "# Once fitted, the vectorizer has built a dictionary of feature indices:\n",
    "# The index value of a word in the vocabulary is linked to its frequency in the whole training corpus.\n",
    "count_vect.vocabulary_.get(u'algorithm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('00', 134)\n",
      "('000', 92)\n",
      "('0000', 1)\n",
      "('0000001200', 2)\n",
      "('000005102000', 1)\n",
      "('0001', 3)\n",
      "('000100255pixel', 1)\n",
      "('00014', 1)\n",
      "('000406', 1)\n",
      "('0007', 1)\n"
     ]
    }
   ],
   "source": [
    "# print counts of each word\n",
    "import numpy as np\n",
    "for wc in zip(count_vect.get_feature_names()[:10],\n",
    "    np.asarray(X_train_counts.sum(axis=0)).ravel()[:10]):\n",
    "    print(wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2257, 35788)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downscale the term frequencies for words that appear many times\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_new = ['God is love', 'OpenGL on the GPU is fast']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "predicted = clf.predict(X_new_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love' => soc.religion.christian\n",
      "'OpenGL on the GPU is fast' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "for doc,category in zip(docs_new, predicted):\n",
    "    print(\"%r => %s\" %(doc, twenty_train.target_names[category]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create Naive Bayes pipeline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 3 ..., 2 2 2]\n",
      "1 alt.atheism\n",
      "1 comp.graphics\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.target)\n",
    "for idx, name in zip(twenty_train.target[0:2], twenty_train.target_names[0:2]):\n",
    "    print (\"{} {}\".format(idx, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...inear_tf=False, use_idf=True)), ('clf', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([\n",
    "    ('vect',  CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "text_clf.fit(twenty_train.data, twenty_train.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83488681757656458"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "twenty_test = fetch_20newsgroups(subset='test', \n",
    "                                 categories=categories, \n",
    "                                 shuffle=True, \n",
    "                                 random_state=42)\n",
    "docs_test = twenty_test.data\n",
    "predicted = text_clf.predict(docs_test)\n",
    "np.mean(predicted==twenty_test.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create SVM pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1502"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xcode/miniconda3/envs/ffma/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:117: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.73501997336884151"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "train_count= 100\n",
    "text_clf_svm = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfid', TfidfTransformer()),\n",
    "    ('clf-svm', SGDClassifier(loss='hinge', penalty = 'l2', \n",
    "                              alpha=1e-3, n_iter=5, random_state=42))\n",
    "])\n",
    "_ = text_clf_svm.fit(twenty_train.data[:train_count], twenty_train.target[:train_count])\n",
    "predicted_svm = text_clf_svm.predict(twenty_test.data)\n",
    "np.mean(predicted_svm == twenty_test.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tune Classifiers using Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'vect__ngram_range': [(1, 1), (1, 2)],\n",
    "              'tfidf__use_idf': (True, False),\n",
    "              'clf__alpha': (1e-2, 1e-3),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs = -1)\n",
    "gs_clf = gs_clf.fit(twenty_train.data[:train_count], twenty_train.target[:train_count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score: 0.8\n",
      "\n",
      "best score params: {'clf__alpha': 0.001, 'tfidf__use_idf': True, 'vect__ngram_range': (1, 1)} \n"
     ]
    }
   ],
   "source": [
    "print(\"best score: {}\\n\".format(gs_clf.best_score_))\n",
    "print(\"best score params: {} \".format(gs_clf.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find words with greatest mutual information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "categories = ['talk.religion.misc',\n",
    "              'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      categories=categories)\n",
    "\n",
    "X, Y = newsgroups_train.data, newsgroups_train.target\n",
    "cv = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                     max_features=10000,\n",
    "                                     stop_words='english')\n",
    "X_vec = cv.fit_transform(X)\n",
    "\n",
    "res = dict(zip(cv.get_feature_names(),\n",
    "               mutual_info_classif(X_vec, Y, discrete_features=True)\n",
    "               ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bible\t\t 0.07232747959557144\n",
      "christ\t\t 0.05729373368021909\n",
      "christian\t\t 0.12862867565281702\n",
      "christians\t\t 0.06851132861181007\n",
      "god\t\t 0.12252523919766867\n",
      "gov\t\t 0.05354727448578558\n",
      "graphics\t\t 0.13044709565039875\n",
      "jesus\t\t 0.09245436105573257\n",
      "launch\t\t 0.05988217938744486\n",
      "moon\t\t 0.06497778107255724\n",
      "morality\t\t 0.05023510439412315\n",
      "nasa\t\t 0.11146392824624819\n",
      "orbit\t\t 0.087254803670583\n",
      "people\t\t 0.06811837023435494\n",
      "religion\t\t 0.06769561709612532\n",
      "shuttle\t\t 0.05344097661835926\n",
      "space\t\t 0.20115901737978983\n",
      "thanks\t\t 0.060202010019767334\n"
     ]
    }
   ],
   "source": [
    "for k,v in res.items():\n",
    "    if v > 0.05:\n",
    "        print(\"{}\\t\\t {}\".format(k,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
